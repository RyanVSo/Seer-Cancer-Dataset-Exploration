{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt4bISOUABF0"
      },
      "source": [
        "# 1. Preprocessing\n",
        "Look through your data for outliers, perform standardization/normalization and handle missing values.  Use dimensionality reduction if your dataset has a lot of features.+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9Cfgn8LPABF2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/Spring-2024/Big Data Science/hw5/Breast_Cancer_dataset.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79cN3rxsAfpX",
        "outputId": "5a38799d-428e-4cbd-e559-bf26e39e532e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxczVmTzABF3",
        "outputId": "9e58026f-6384-46b1-9ff5-183a5fd97233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4024\n",
            "Number of outliers: 224\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3813 entries, 0 to 3812\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Age                     3813 non-null   float64\n",
            " 1   Race                    3813 non-null   object \n",
            " 2   Marital Status          3813 non-null   object \n",
            " 3   T Stage                 3813 non-null   object \n",
            " 4   N Stage                 3813 non-null   object \n",
            " 5   6th Stage               3813 non-null   object \n",
            " 6   differentiate           3813 non-null   object \n",
            " 7   Grade                   3813 non-null   object \n",
            " 8   A Stage                 3813 non-null   object \n",
            " 9   Tumor Size              3813 non-null   float64\n",
            " 10  Estrogen Status         3813 non-null   object \n",
            " 11  Progesterone Status     3813 non-null   object \n",
            " 12  Regional Node Examined  3813 non-null   float64\n",
            " 13  Reginol Node Positive   3813 non-null   float64\n",
            " 14  Survival Months         3813 non-null   float64\n",
            " 15  Status                  3813 non-null   object \n",
            "dtypes: float64(5), object(11)\n",
            "memory usage: 476.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Read the CSV file\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "print(len(df))\n",
        "\n",
        "numerical_columns = df.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# Calculate z-scores for numerical columns\n",
        "z_scores = (numerical_columns - numerical_columns.mean()) / numerical_columns.std()\n",
        "\n",
        "# Identify outliers\n",
        "outliers = (z_scores > 3) | (z_scores < -3)\n",
        "\n",
        "# Count number of outliers\n",
        "num_outliers = outliers.sum().sum()\n",
        "print(f\"Number of outliers: {num_outliers}\")\n",
        "\n",
        "# Replace outliers with None\n",
        "df = df[~outliers.any(axis=1)]\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "numerical_columns = df.select_dtypes(include=['int64', 'float64'])\n",
        "numerical_columns_imputed = imputer.fit_transform(numerical_columns)\n",
        "\n",
        "# Standardization/Normalization\n",
        "scaler = StandardScaler()  # or MinMaxScaler for normalization\n",
        "numerical_columns_scaled = scaler.fit_transform(numerical_columns_imputed)\n",
        "\n",
        "# Replace numerical columns in the original DataFrame with processed numerical columns\n",
        "df[numerical_columns.columns] = numerical_columns_scaled\n",
        "\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btYn_DkYABF4"
      },
      "source": [
        "# 2. Modeling [15] – For this step you can use tools and/or libraries\n",
        "Apply the Feature Selection and Feature Ranking Techniques we covered in class and/or a combination of both approaches.\n",
        "Train the following algorithms on your dataset (feel free to experiment with more!)\n",
        "\n",
        "NOTE: For each model used, be sure to include a 1-2 line summary as well as the pros and cons of each algorithm and list out its main hyperparameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "_TPSmEWYFSyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "df_encoded = pd.get_dummies(df)\n",
        "\n",
        "X = df_encoded.iloc[:,0:15]  #independent columns\n",
        "Y = df_encoded.iloc[:,-1]    #target column\n",
        "print(Y)\n",
        "\n",
        "# Apply SelectKBest class to extract top 10 best features\n",
        "bestfeatures = SelectKBest(score_func=mutual_info_classif, k=10)\n",
        "fit = bestfeatures.fit(X,Y)\n",
        "\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "\n",
        "# Concat two dataframes for better visualization\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  # Naming the dataframe columns\n",
        "\n",
        "top_10_features = featureScores.nlargest(10,'Score')  # Get 10 best features\n",
        "print(top_10_features)\n",
        "\n",
        "# Create a new dataframe with only the top 10 features\n",
        "df_top_10 = df_encoded[top_10_features['Specs'].values]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3df618-854f-41b7-d1b0-671796dcea31",
        "id": "rTJed10uFSy4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       False\n",
            "1       False\n",
            "2       False\n",
            "3       False\n",
            "4       False\n",
            "        ...  \n",
            "3808    False\n",
            "3809    False\n",
            "3810    False\n",
            "3811    False\n",
            "3812    False\n",
            "Name: Status_Dead, Length: 3813, dtype: bool\n",
            "                       Specs     Score\n",
            "4            Survival Months  0.126997\n",
            "3      Reginol Node Positive  0.020227\n",
            "1                 Tumor Size  0.016960\n",
            "13               T Stage _T1  0.008197\n",
            "5                 Race_Black  0.007908\n",
            "8    Marital Status_Divorced  0.006258\n",
            "9     Marital Status_Married  0.002490\n",
            "2     Regional Node Examined  0.002370\n",
            "12    Marital Status_Widowed  0.002085\n",
            "10  Marital Status_Separated  0.001548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS2wYzIyABF4"
      },
      "source": [
        "# 2.1\tKNN (this should be implemented from scratch, do NOT use in-built libraries)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predicted_labels = [self._predict(x) for x in X]\n",
        "        return np.array(predicted_labels)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # Compute distances between x and all examples in the training set\n",
        "        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]\n",
        "        # Sort by distance and return indices of the first k neighbors\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        # Extract the labels of the k nearest neighbor training samples\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        # return the most common class label\n",
        "        most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
        "        return most_common\n"
      ],
      "metadata": {
        "id": "jCr6skyNBvM-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_top_10.columns:\n",
        "    if df_top_10[col].dtype == bool:\n",
        "        df_top_10[col] = df_top_10[col].astype(int)\n",
        "\n",
        "Y = Y.astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_top_10, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of KNN\n",
        "knn = KNN(k=3)\n",
        "\n",
        "# Fit the model to the training data\n",
        "knn.fit(X_train.values, y_train.values)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = knn.predict(X_test.values)"
      ],
      "metadata": {
        "id": "rJkYif5PGEO4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "print(f'Accuracy: {accuracy(y_test, predictions)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJMAW6Z8LP1W",
        "outputId": "ce0997db-ace7-4eed-8718-1ec1ea081c83"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Pros and Cons: KNN is simple to understand and implement, and it doesn’t require any training phase. However, it can be computationally expensive and slow for large datasets, and its performance can be significantly impacted by the choice of the distance metric and the value of K.\n",
        "\n",
        " Main Hyperparameters: K"
      ],
      "metadata": {
        "id": "dUOr2qCfR8tf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IETo0opeABF5"
      },
      "source": [
        "# 2.2 Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPJzz9PjABF6",
        "outputId": "176f3a06-9300-473c-98f7-54df605ee81e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8768020969855832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-f4082e81989e>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.drop(categorical_cols, axis=1, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "#X = df.drop('Status', axis=1)  # Feature columns\n",
        "#y = Y\n",
        "X = df_top_10\n",
        "y = Y\n",
        "\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)  # Drop first category to avoid multicollinearity\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))\n",
        "X_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "X.drop(categorical_cols, axis=1, inplace=True)\n",
        "X = pd.concat([X, X_encoded], axis=1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Naive Bayes classifier (assuming the feature column is categorical)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros and Cons: Naive Bayes is fast, easy to implement, and performs well with high-dimensional datasets. However, its assumption of feature independence is often violated in real-world data, which can negatively impact its performance.\n",
        "\n",
        "Main Hyperparameters: Alpha"
      ],
      "metadata": {
        "id": "VGjppUf5SLrm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3wcqIaKABF6"
      },
      "source": [
        "# 2.3 C4.5 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install c45-decision-tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu-siUnnOAfN",
        "outputId": "3881ad85-f325-4208-91c8-45441b5f3da4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting c45-decision-tree\n",
            "  Downloading c45_decision_tree-1.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: c45-decision-tree\n",
            "Successfully installed c45-decision-tree-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from C45 import C45Classifier\n",
        "import pandas as pd\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_top_10, Y, test_size=0.2, random_state=42)\n",
        "model = C45Classifier()\n",
        "model.fit(X_train, y_train)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxnKgPNLOHHm",
        "outputId": "1dfd23cb-68bb-4718-ec3f-0d737d568050"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result: \n",
            "Total accuracy:  0.7352555701179554\n",
            "Accuracy  0 :  0.746177370030581\n",
            "Accuracy  1 :  0.6697247706422018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros and Cons:  C4.5 can handle both categorical and continuous data, and it uses a post-pruning approach to avoid overfitting. However, it can be sensitive to small changes in the data, leading to different trees, and it may not perform well with unbalanced datasets.\n",
        "\n",
        "Main Hyperparameter: Criterion and max_depth"
      ],
      "metadata": {
        "id": "PGFEtubwSegI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJIK3zeABF6"
      },
      "source": [
        "# 2.4 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_top_10.values\n",
        "y = Y.values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier and fit it to the training data\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Accuracy: {accuracy(y_test, y_pred)*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyJiJzk2PI4r",
        "outputId": "cf54a74a-e41d-4540-9ce5-825dfa0430d5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros and Cons: Random Forest is robust to overfitting and can handle large datasets with high dimensionality. However, it can be computationally intensive and slower to train and predict than simpler models, and it may not perform well with very sparse data or datasets with many categorical variables.\n",
        "\n",
        "Main Hyperparameters: n_estimators, criterion, max_depth"
      ],
      "metadata": {
        "id": "Cnca4Nq6SqXV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cC9mkSeABF7"
      },
      "source": [
        "# 2.5 Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4WfIF9UABF7",
        "outputId": "c4942194-0d94-42ef-d706-7c4e0e24f4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.43%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_top_10.values\n",
        "y = Y.values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a gradient boosting classifier and fit it to the training data\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Accuracy: {accuracy(y_test, y_pred)*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros and Cons: Gradient Boosting can provide high predictive accuracy and is effective with unbalanced datasets. However, it can be prone to overfitting if not properly regularized, and it can be more computationally intensive and slower to train than other models.\n",
        "\n",
        "Main Hyperparameter: n_estimators, learning_rate, max_depth"
      ],
      "metadata": {
        "id": "HNyc5nrASyqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "1-cIfpnSP5x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = df_top_10.values\n",
        "y = Y.values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for RandomForestClassifier\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object for RandomForestClassifier\n",
        "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters for RandomForestClassifier: \", grid_search_rf.best_params_)\n",
        "print(\"Best score for RandomForestClassifier: \", grid_search_rf.best_score_)\n",
        "\n",
        "# Predict on the test data and print the performance metrics\n",
        "y_pred_rf = grid_search_rf.predict(X_test)\n",
        "print(\"Performance metrics for RandomForestClassifier:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Define the parameter grid for GradientBoostingClassifier\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'max_depth': [1, 3, 5]\n",
        "}\n",
        "\n",
        "# Create a GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object for GradientBoostingClassifier\n",
        "grid_search_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters for GradientBoostingClassifier: \", grid_search_gb.best_params_)\n",
        "print(\"Best score for GradientBoostingClassifier: \", grid_search_gb.best_score_)\n",
        "\n",
        "# Predict on the test data and print the performance metrics\n",
        "y_pred_gb = grid_search_gb.predict(X_test)\n",
        "print(\"Performance metrics for GradientBoostingClassifier:\")\n",
        "print(classification_report(y_test, y_pred_gb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT30Ww6KQ1f1",
        "outputId": "326be7b9-e820-41a3-e529-17d23e83068b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForestClassifier:  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Best score for RandomForestClassifier:  0.9036065573770491\n",
            "Performance metrics for RandomForestClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       654\n",
            "           1       0.77      0.50      0.61       109\n",
            "\n",
            "    accuracy                           0.91       763\n",
            "   macro avg       0.85      0.74      0.78       763\n",
            "weighted avg       0.90      0.91      0.90       763\n",
            "\n",
            "Best parameters for GradientBoostingClassifier:  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 200}\n",
            "Best score for GradientBoostingClassifier:  0.9022950819672131\n",
            "Performance metrics for GradientBoostingClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94       654\n",
            "           1       0.73      0.51      0.60       109\n",
            "\n",
            "    accuracy                           0.90       763\n",
            "   macro avg       0.83      0.74      0.77       763\n",
            "weighted avg       0.89      0.90      0.90       763\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning Results:\n",
        "\n",
        "Best parameters for RandomForestClassifier:  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
        "\n",
        "Best score for RandomForestClassifier:  0.9036065573770491\n",
        "\n",
        "Best parameters for GradientBoostingClassifier:  {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 200}\n",
        "\n",
        "Best score for GradientBoostingClassifier:  0.9022950819672131\n"
      ],
      "metadata": {
        "id": "T_d4tBPSWVHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "LMvyLvRDREDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'Algorithm Name': ['KNN', 'Naive Bayes', 'C4.5', 'Random Forest', 'Gradient Boosting'],\n",
        "    'Accuracies': ['88.74%', '87.68%', '73.54%', '89.91%', '90.43%']\n",
        "}\n",
        "\n",
        "# Create the DataFrame\n",
        "results = pd.DataFrame(results)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gG_ZPXh_RIzF",
        "outputId": "f9c918af-aaed-4b2f-bd7c-aaa989010d3b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Algorithm Name Accuracies\n",
              "0                KNN     88.74%\n",
              "1        Naive Bayes     87.68%\n",
              "2               C4.5     73.54%\n",
              "3      Random Forest     89.91%\n",
              "4  Gradient Boosting     90.43%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4dcbeb3-6811-4fdb-aed9-fc0e7bb72f37\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm Name</th>\n",
              "      <th>Accuracies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN</td>\n",
              "      <td>88.74%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>87.68%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C4.5</td>\n",
              "      <td>73.54%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>89.91%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>90.43%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4dcbeb3-6811-4fdb-aed9-fc0e7bb72f37')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4dcbeb3-6811-4fdb-aed9-fc0e7bb72f37 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4dcbeb3-6811-4fdb-aed9-fc0e7bb72f37');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36cb761c-9a1a-4272-ad1f-08ea28762b7a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36cb761c-9a1a-4272-ad1f-08ea28762b7a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36cb761c-9a1a-4272-ad1f-08ea28762b7a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Algorithm Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Naive Bayes\",\n          \"Gradient Boosting\",\n          \"C4.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracies\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"87.68%\",\n          \"90.43%\",\n          \"73.54%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "results.groupby('Algorithm Name').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGdCAYAAABUyBieAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5bUlEQVR4nO3deXRN9+L//9dJIgMyoZIgpRoSNKjxkvtRUxvaanXSi7pSSltzUUPR1DwU1aJ1G63opaUo7TWEIjGEGioxtJHWVLRBTYkEIcn+/uGX83NqykmTHY7nY629Vs8+77PPa+9avPLeQyyGYRgCAAAATOBU1AEAAABw/6B8AgAAwDSUTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RN3FcMwlJaWJn73AQAAjonyibvKhQsX5O3trQsXLhR1FAAAUAgonwAAADAN5RMAAACmoXwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwjUtRBwBupu+iGnItzs9GAAAUlP+0/62oI0hi5hMAAAAmonwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+C5jFYtGyZcuKOgYAAMBdyeHKZ0REhCwWiywWi4oVK6aHHnpIgwYN0uXLl4s6WqG6fr+vXw4cOFCkmdq2bVtk3w8AAO4+LkUdoDC0atVKc+bM0dWrV/Xjjz+qc+fOslgsmjhxYlFHK1S5+329Bx54IF/bunLlilxdXQsiFgAAgJXDzXxKkpubm/z9/RUYGKi2bduqZcuW+v77763vnzlzRu3bt1f58uVVvHhxhYaG6quvvrLZRtOmTdWnTx8NGjRIpUqVkr+/v9577z2bMb/++quaNGkid3d3Va9e3eY7cu3du1fNmzeXh4eHSpcure7duys9Pd36fu7s4Lhx4+Tn5ycfHx+NGjVKWVlZevvtt1WqVClVqFDhhlJ5u/2+fnF2dpYkbdiwQQ0aNJCbm5sCAgI0ZMgQZWVl2exvr1691K9fP5UpU0bh4eGSpH379ql169YqWbKk/Pz81KlTJ50+fdr6ucWLFys0NNS6fy1btlRGRobee+89zZ07V99++611FjYuLu6O+wAAABybQ5bP6+3bt09btmyxmcW7fPmy6tatqxUrVmjfvn3q3r27OnXqpO3bt9t8du7cuSpRooS2bdumSZMmadSoUdaCmZOTo+eff16urq7atm2bZs2apcGDB9t8PiMjQ+Hh4fL19dWOHTu0aNEirV27Vr169bIZt379ev3xxx/auHGjpk6dqsjISD399NPy9fXVtm3b9MYbb+j111/X8ePH83UMfv/9dz355JOqX7++du/erU8++USfffaZxowZc8P+urq6Kj4+XrNmzdL58+fVvHlzPfroo9q5c6diYmJ08uRJtWvXTpKUkpKi9u3bq0uXLkpKSlJcXJyef/55GYahgQMHql27dmrVqpVSUlKUkpKixo0b5ys/AABwHBbDMIyiDlGQIiIiNG/ePLm7uysrK0uZmZlycnLS119/rRdeeOGWn3v66acVEhKiyZMnS7o2E5idna1NmzZZxzRo0EDNmzfXhAkTtGbNGj311FP67bffVK5cOUlSTEyMWrduraVLl6pt27aKiorS4MGDdezYMZUoUUKStHLlSrVp00Z//PGH/Pz8FBERobi4OB06dEhOTtd+FggJCVHZsmW1ceNGSVJ2dra8vb01e/Zs/etf/7rjfudq3bq1Fi1apGHDhmnJkiVKSkqSxWKRJH388ccaPHiwUlNT5eTkpKZNmyotLU27du2yfn7MmDHatGmTVq9ebV13/PhxBQYGKjk5Wenp6apbt66OHDmiihUr3jTT+fPnb3sDVmZmpjIzM62v09LSFBgYqIjZFeRa3OF/NgIAwDT/af9bUUeQ5KDXfDZr1kyffPKJMjIy9MEHH8jFxcWmeGZnZ2vcuHH6+uuv9fvvv+vKlSvKzMxU8eLFbbZTs2ZNm9cBAQE6deqUJCkpKUmBgYHW4ilJjRo1shmflJSkWrVqWYunJIWFhSknJ0fJycny8/OTJNWoUcNaPCXJz89PjzzyiPW1s7OzSpcubf3uO+13rtzvTUpKUqNGjazFMzdHenq6jh8/rgcffFCSVLduXZvt7d69W7GxsSpZsuQN33Xw4EE98cQTatGihUJDQxUeHq4nnnhCL774onx9fW+b83rjx4/XyJEj8zweAADc2xxyaqlEiRIKCgpSrVq19Pnnn2vbtm367LPPrO+///77+vDDDzV48GDFxsYqMTFR4eHhunLlis12ihUrZvPaYrEoJyenwPPe7Hvy8925+527BAQE2JXj+pIsSenp6WrTpo0SExNtltxrXZ2dnfX9999r1apVql69uqZPn67g4GAdPnw4z985dOhQpaamWpdjx47ZlRkAANxbHLJ8Xs/JyUnvvPOOhg8frkuXLkmS4uPj9eyzz+qVV15RrVq1VLlyZf3yyy92bbdatWo6duyYUlJSrOt++OGHG8bs3r1bGRkZ1nXx8fFycnJScHDw39gr+1SrVk1bt27V9VdYxMfHy9PTUxUqVLjl5+rUqaOffvpJlSpVsim1QUFB1qJqsVgUFhamkSNHKiEhQa6urlq6dKkkydXVVdnZ2bfN5ubmJi8vL5sFAAA4Locvn5L00ksvydnZWTNnzpQkValSRd9//722bNmipKQkvf766zp58qRd22zZsqWqVq2qzp07a/fu3dq0aZOGDRtmM6Zjx45yd3dX586dtW/fPsXGxqp3797q1KmT9ZS7GXr06KFjx46pd+/e2r9/v7799ltFRkaqf//+Nqf7/6pnz546e/as2rdvrx07dujgwYNavXq1Xn31VWVnZ2vbtm0aN26cdu7cqaNHj+qbb77Rn3/+qWrVqkmSKlWqpD179ig5OVmnT5/W1atXzdplAABwl7ovyqeLi4t69eqlSZMmKSMjQ8OHD1edOnUUHh6upk2byt/f3+6HoTs5OWnp0qW6dOmSGjRooNdee01jx461GVO8eHGtXr1aZ8+eVf369fXiiy+qRYsWmjFjRgHu3Z2VL19eK1eu1Pbt21WrVi298cYb6tq1q4YPH37bz5UrV07x8fHKzs7WE088odDQUPXr108+Pj5ycnKSl5eXNm7cqCeffFJVq1bV8OHDNWXKFLVu3VqS1K1bNwUHB6tevXp64IEHFB8fb8buAgCAu5jD3e2Oe1taWpq8vb252x0AgAJ2t9ztzr/uAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8AgAAwDSUTwAAAJjGYhiGUdQhgFxpaWny9vZWamqqvLy8ijoOAAAoYMx8AgAAwDSUTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RMAAACmoXwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8AgAAwDSUTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RMAAACmoXwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAal6IOANzMyfof6qKze1HHAADAYfj//HZRR5DEzCcAAABMRPkEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8mqBp06bq169fUccAAAAocpTPW4iIiJDFYtGECRNs1i9btkwWi8WubX3zzTcaPXp0Qca7QW7e3KV06dJq1aqV9uzZU6jfCwAAYA/K5224u7tr4sSJOnfu3N/aTqlSpeTp6VlAqW6tVatWSklJUUpKitatWycXFxc9/fTThf69AAAAeUX5vI2WLVvK399f48ePv+WYM2fOqH379ipfvryKFy+u0NBQffXVVzZjrj/t/s4776hhw4Y3bKdWrVoaNWqU9fXs2bNVrVo1ubu7KyQkRB9//PEd87q5ucnf31/+/v6qXbu2hgwZomPHjunPP/+0jhk8eLCqVq2q4sWLq3LlyhoxYoSuXr0qSTpy5IicnJy0c+dOm+1OmzZNFStWVE5OjiRp3759at26tUqWLCk/Pz916tRJp0+fto5fvHixQkND5eHhodKlS6tly5bKyMi4Y34AAOD4KJ+34ezsrHHjxmn69Ok6fvz4TcdcvnxZdevW1YoVK7Rv3z51795dnTp10vbt2286vmPHjtq+fbsOHjxoXffTTz9pz5496tChgyRp/vz5evfddzV27FglJSVp3LhxGjFihObOnZvn7Onp6Zo3b56CgoJUunRp63pPT09FR0fr559/1ocffqioqCh98MEHkqRKlSqpZcuWmjNnjs225syZo4iICDk5Oen8+fNq3ry5Hn30Ue3cuVMxMTE6efKk2rVrJ0lKSUlR+/bt1aVLFyUlJSkuLk7PP/+8DMPIc3YAAOC4LAat4KYiIiJ0/vx5LVu2TI0aNVL16tX12WefadmyZXruueduW6aefvpphYSEaPLkyZKuzXzWrl1b06ZNkyTVrl1bL7zwgkaMGCHp2mzo+vXr9cMPP0iSgoKCNHr0aLVv3966zTFjxmjlypXasmXLLfPOmzdP7u7ukqSMjAwFBARo+fLlqlOnzi2zTp48WQsWLLDOdn799dd64403lJKSIjc3N+3atUv16tXToUOHVKlSJY0ZM0abNm3S6tWrrds4fvy4AgMDlZycrPT0dNWtW1dHjhxRxYoV73SYlZmZqczMTOvrtLQ0BQYG6peqo+Tp7H7HzwMAgLzx//ntoo4giZnPPJk4caLmzp2rpKSkG97Lzs7W6NGjFRoaqlKlSqlkyZJavXq1jh49esvtdezYUV9++aUkyTAMffXVV+rYsaOka6Xx4MGD6tq1q0qWLGldxowZYzNbejPNmjVTYmKiEhMTtX37doWHh6t169b67bffrGMWLlyosLAw+fv7q2TJkho+fLhN1rZt28rZ2VlLly6VJEVHR6tZs2aqVKmSJGn37t2KjY21yRYSEiJJOnjwoGrVqqUWLVooNDRUL730kqKiom57zez48ePl7e1tXQIDA2+7jwAA4N5G+cyDJk2aKDw8XEOHDr3hvffff18ffvihBg8erNjYWCUmJio8PFxXrly55fbat2+v5ORk7dq1S1u2bNGxY8f08ssvS7p2ulySoqKirEUyMTFR+/bts86M3kqJEiUUFBSkoKAg1a9fX7Nnz1ZGRoaioqIkSVu3blXHjh315JNPavny5UpISNCwYcNssrq6uurf//635syZoytXrujLL79Uly5drO+np6erTZs2NtkSExP166+/qkmTJnJ2dtb333+vVatWqXr16po+fbqCg4N1+PDhm2YeOnSoUlNTrcuxY8duu48AAODe5lLUAe4VEyZMUO3atRUcHGyzPj4+Xs8++6xeeeUVSVJOTo5++eUXVa9e/ZbbqlChgh577DHNnz9fly5d0uOPP66yZctKkvz8/FSuXDkdOnTIOhuaXxaLRU5OTrp06ZIkacuWLapYsaKGDRtmHXP9rGiu1157TY888og+/vhjZWVl6fnnn7e+V6dOHS1ZskSVKlWSi8vN//hYLBaFhYUpLCxM7777ripWrKilS5eqf//+N4x1c3OTm5vb39pPAABw76B85lFoaKg6duyojz76yGZ9lSpVtHjxYm3ZskW+vr6aOnWqTp48edvyKV079R4ZGakrV65Yb/jJNXLkSPXp00fe3t5q1aqVMjMztXPnTp07d+6mBS5XZmamTpw4IUk6d+6cZsyYYZ2pzM169OhRLViwQPXr19eKFSusp9evV61aNf3jH//Q4MGD1aVLF3l4eFjf69mzp6KiotS+fXsNGjRIpUqV0oEDB7RgwQLNnj1bO3fu1Lp16/TEE0+obNmy2rZtm/78809Vq1bt9gcYAADcFzjtbodRo0ZZHzeUa/jw4apTp47Cw8PVtGlT+fv7q23btnfc1osvvqgzZ87o4sWLN4x/7bXXNHv2bM2ZM0ehoaF67LHHFB0drYceeui224yJiVFAQIACAgLUsGFD7dixQ4sWLVLTpk0lSc8884zeeust9erVS7Vr19aWLVusNz39VdeuXXXlyhWbU+6SVK5cOcXHxys7O1tPPPGEQkND1a9fP/n4+MjJyUleXl7auHGjnnzySVWtWlXDhw/XlClT1Lp16zseEwAA4Pi42x03NXr0aC1atMj035CUlpYmb29v7nYHAKCAcbc77krp6enat2+fZsyYod69exd1HAAA4GAon7DRq1cv1a1bV02bNr3hlDsAAMDfxWl33FU47Q4AQOHgtDsAAADuO5RPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0/IYj3FVyf8NRamqqvLy8ijoOAAAoYPma+dy0aZNeeeUVNWrUSL///rsk6b///a82b95coOEAAADgWOwun0uWLFF4eLg8PDyUkJCgzMxMSVJqaqrGjRtX4AEBAADgOOwun2PGjNGsWbMUFRWlYsWKWdeHhYVp165dBRoOAAAAjsXu8pmcnKwmTZrcsN7b21vnz58viEwAAABwUHaXT39/fx04cOCG9Zs3b1blypULJBQAAAAck93ls1u3burbt6+2bdsmi8WiP/74Q/Pnz9fAgQP15ptvFkZGAAAAOAgXez8wZMgQ5eTkqEWLFrp48aKaNGkiNzc3DRw4UL179y6MjAAAAHAQ+X7O55UrV3TgwAGlp6erevXqKlmyZEFnw32I53wCAODY7J75zOXq6qrq1asXZBYAAAA4OLvL5+XLlzV9+nTFxsbq1KlTysnJsXmfxy0BAADgVuwun127dtWaNWv04osvqkGDBrJYLIWRCwAAAA7I7ms+vb29tXLlSoWFhRVWJtzHuOYTAADHZvejlsqXLy9PT8/CyAIAAAAHZ3f5nDJligYPHqzffvutMPIAAADAgdl9zWe9evV0+fJlVa5cWcWLF7f5/e6SdPbs2QILBwAAAMdid/ls3769fv/9d40bN05+fn7ccAQAAIA8s7t8btmyRVu3blWtWrUKIw8AAAAcmN3XfIaEhOjSpUuFkQUAAAAOzu7yOWHCBA0YMEBxcXE6c+aM0tLSbBYAAADgVux+zqeT07W++tdrPQ3DkMViUXZ2dsGlw32H53wCAODY7L7mMzY2tjByAAAA4D5g98wnUJiY+QQAwLHZPfOZ6+LFizp69KiuXLlis75mzZp/OxQAAAAck93l888//9Srr76qVatW3fR9rvkEAADArdh9t3u/fv10/vx5bdu2TR4eHoqJidHcuXNVpUoVfffdd4WREQAAAA7C7pnP9evX69tvv1W9evXk5OSkihUr6vHHH5eXl5fGjx+vp556qjByAgAAwAHYPfOZkZGhsmXLSpJ8fX31559/SpJCQ0O1a9eugk0HAAAAh2J3+QwODlZycrIkqVatWvrPf/6j33//XbNmzVJAQECBBwQAAIDjsPu0e9++fZWSkiJJioyMVKtWrTR//ny5uroqOjq6oPMBAADAgfzt53xevHhR+/fv14MPPqgyZcoUVC7cp3jOJwAAjo2HzOOuQvkEAMCx5fm0+6hRo/I07t133813GAAAADi2PM98Pvroo7d9/5dfftHly5d5yDz+FmY+AQBwbHme+UxISLjp+sTERA0ZMkQ//fSTunXrVmDBAAAA4HjsftRSrsOHD+uVV15R/fr15e3trZ9++kmzZs0qyGwAAABwMHaXz9OnT6t3794KCQlRSkqKtmzZooULF6pKlSqFkQ8AAAAOJM+n3TMyMjR58mRNnTpVQUFB+t///qcnnniiMLPhPjZiSIzc3IoXdQwAABzGpA+eLuoIkuwonw8//LAuXLig3r17q3379rJYLNqzZ88N42rWrFmgAQEAAOA48ny3u5PT/3+G3mKx6PqP5b62WCzc7Y6/Jfdu9z5vLmTmEwCAAnTPzXwePny4MHMAAADgPpDn8lmxYsXCzAEAAID7QL4ftQQAAADYi/IJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBp8ny3e64zZ87o3XffVWxsrE6dOqWcnByb98+ePVtg4QAAAOBY7C6fnTp10oEDB9S1a1f5+fnJYrEURi4AAAA4ILvL56ZNm7R582bVqlWrMPIAAADAgdl9zWdISIguXbpUGFkAAADg4Owunx9//LGGDRumDRs26MyZM0pLS7NZcO+IiIhQ27ZtbdYtXrxY7u7umjJliiIiImSxWDRhwgSbMcuWLbO53CIuLk4Wi0U1atRQdna2zVgfHx9FR0cX1i4AAIB7jN3l08fHR2lpaWrevLnKli0rX19f+fr6ysfHR76+voWRESaZPXu2OnbsqE8++UQDBgyQJLm7u2vixIk6d+7cHT9/6NAhffHFF4UdEwAA3MPsvuazY8eOKlasmL788ktuOHIgkyZNUmRkpBYsWKDnnnvOur5ly5Y6cOCAxo8fr0mTJt12G71791ZkZKQ6dOggNze3wo4MAADuQXaXz3379ikhIUHBwcGFkQdFYPDgwfr444+1fPlytWjRwuY9Z2dnjRs3Th06dFCfPn1UoUKFW26nX79+mjdvnqZPn66BAwfm6bszMzOVmZlpfc2lGwAAODa7T7vXq1dPx44dK4wsKAKrVq3SpEmT9O23395QPHM999xzql27tiIjI2+7reLFiysyMlLjx49Xampqnr5//Pjx8vb2ti6BgYF27wMAALh32F0+e/furb59+yo6Olo//vij9uzZY7Pg3lKzZk1VqlRJkZGRSk9Pv+W4iRMnau7cuUpKSrrt9rp27arSpUtr4sSJefr+oUOHKjU11brwgw0AAI7N7tPuL7/8siSpS5cu1nUWi0WGYchisdxwtzPubuXLl9fixYvVrFkztWrVSqtWrZKnp+cN45o0aaLw8HANHTpUERERt9yei4uLxo4dq4iICPXq1euO3+/m5sb1oQAA3EfsLp+HDx8ujBwoQhUrVtSGDRusBTQmJuamBXTChAmqXbv2Ha/3femll/T+++9r5MiRhRUZAADco+wunxUrViyMHChigYGBiouLU7NmzRQeHq6YmJgbxoSGhqpjx4766KOP7ri9CRMmKDw8vDCiAgCAe5jd5VOSfv31V8XGxurUqVPKycmxee/dd98tkGAwX4UKFWwKaEBAwA1jRo0apYULF95xW82bN1fz5s21Zs2awogKAADuURbDMAx7PhAVFaU333xTZcqUkb+/v81zPi0Wi3bt2lXgIXH/SEtLk7e3t/q8uVBubsWLOg4AAA5j0gdPF3UESfmY+RwzZozGjh2rwYMHF0YeAAAAODC7H7V07tw5vfTSS4WRBQAAAA7O7vL50ksvcR0fAAAA8iVPp92vv7s5KChII0aM0A8//KDQ0FAVK1bMZmyfPn0KNiEAAAAcRp5uOHrooYfytjGLRYcOHfrboXD/4oYjAAAKxz11wxEPlgcAAEBBsPuaz1GjRunixYs3rL906ZJGjRpVIKEAAADgmOwunyNHjlR6evoN6y9evMivUwQAAMBt2V0+DcOwebB8rt27d6tUqVIFEgoAAACOKc8Pmff19ZXFYpHFYlHVqlVtCmh2drbS09P1xhtvFEpIAAAAOIY8l89p06bJMAx16dJFI0eOlLe3t/U9V1dXVapUSY0aNSqUkAAAAHAMeS6fnTt3lnTtsUuNGze+4fmeAAAAwJ3k6TmfaWlp8vLysv737eSOA/Ij9zmfqamp/FkCAMAB5Wnm09fXVykpKSpbtqx8fHxuesNR7o1I2dnZBR4SAAAAjiFP5XP9+vXWO9ljY2MLNRAAAAAcV57K52OPPSZJysrK0oYNG9SlSxdVqFChUIMBAADA8dj1nE8XFxe9//77ysrKKqw8AAAAcGB2P2S+efPm2rBhQ2FkAQAAgIPL86OWcrVu3VpDhgzR3r17VbduXZUoUcLm/WeeeabAwgEAAMCx5OlRS9dzcrr1ZCl3u+Pv4lFLAAA4NrtnPnNycgojBwAAAO4Ddl/zCQAAAORXvsrnhg0b1KZNGwUFBSkoKEjPPPOMNm3aVNDZAAAA4GDsLp/z5s1Ty5YtVbx4cfXp00d9+vSRh4eHWrRooS+//LIwMgIAAMBB2H3DUbVq1dS9e3e99dZbNuunTp2qqKgoJSUlFWhA3F+44QgAAMdm98znoUOH1KZNmxvWP/PMMzp8+HCBhAIAAIBjsrt8BgYGat26dTesX7t2rQIDAwskFAAAAByT3Y9aGjBggPr06aPExEQ1btxYkhQfH6/o6Gh9+OGHBR4QAAAAjsPuaz4laenSpZoyZYr1+s5q1arp7bff1rPPPlvgAXF/4ZpPAAAcW77KJ1BYKJ8AADg2HjIPAAAA09h9zaevr68sFssN6y0Wi9zd3RUUFKSIiAi9+uqrBRIQAAAAjsPu8vnuu+9q7Nixat26tRo0aCBJ2r59u2JiYtSzZ08dPnxYb775prKystStW7cCDwwAAIB7l93lc/PmzRozZozeeOMNm/X/+c9/tGbNGi1ZskQ1a9bURx99RPkEAACADbtvOCpZsqQSExMVFBRks/7AgQOqXbu20tPTdfDgQdWsWVMZGRkFGhaOjxuOAABwbHbfcFSqVCn973//u2H9//73P5UqVUqSlJGRIU9Pz7+fDgAAAA7F7tPuI0aM0JtvvqnY2FjrNZ87duzQypUrNWvWLEnS999/r8cee6xgkwIAAOCel6/nfMbHx2vGjBlKTk6WJAUHB6t3797W33gE5Ben3QEAcGw8ZB53FconAACOLU+n3dPS0vK8QQoDAAAAbiVP5dPHx+emD5a/nmEYslgsys7OLpBgAAAAcDx5Kp+xsbGFnQMAAAD3gTyVz7zeub5v376/FQYAAACOze7nfP7VhQsX9Omnn6pBgwaqVatWQWQCAACAg8p3+dy4caM6d+6sgIAATZ48Wc2bN9cPP/xQkNkAAADgYOx6yPyJEycUHR2tzz77TGlpaWrXrp0yMzO1bNkyVa9evbAyAgAAwEHkeeazTZs2Cg4O1p49ezRt2jT98ccfmj59emFmAwAAgIPJ88znqlWr1KdPH7355puqUqVKYWYCAACAg8rzzOfmzZt14cIF1a1bVw0bNtSMGTN0+vTpwswGAAAAB2P3r9fMyMjQwoUL9fnnn2v79u3Kzs7W1KlT1aVLF3l6ehZWTtwncn+95o/tLSrpevtfbAAAAPKuavTd8YuA/tbvdk9OTtZnn32m//73vzp//rwef/xxfffddwWZD/cZyicAAIXjbimff+s5n8HBwZo0aZKOHz+ur776qqAyAQAAwEH9rZlPoKAx8wkAQOFwiJlPAAAAwB6UTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RMAAACmoXwCAADANPdl+YyIiFDbtm2tr5s2bap+/foVWZ671XvvvafatWsXdQwAAOBAirx8njhxQn379lVQUJDc3d3l5+ensLAwffLJJ7p48aIpGb755huNHj26QLf514J7u3EWi8W6lC5dWq1atdKePXsKNM+dWCwWLVu2zGbdwIEDtW7dOlNzAAAAx1ak5fPQoUN69NFHtWbNGo0bN04JCQnaunWrBg0apOXLl2vt2rW3/OzVq1cLLEepUqXk6elZYNuzV6tWrZSSkqKUlBStW7dOLi4uevrpp4ssT66SJUuqdOnSRR0DAAA4kCItnz169JCLi4t27typdu3aqVq1aqpcubKeffZZrVixQm3atLGOtVgs+uSTT/TMM8+oRIkSGjt2rLKzs9W1a1c99NBD8vDwUHBwsD788EOb78jOzlb//v3l4+Oj0qVLa9CgQTIMw2bMX0+7Z2ZmauDAgSpfvrxKlCihhg0bKi4uzvp+dHS0fHx8tHr1alWrVk0lS5a0Fkjp2unquXPn6ttvv7XOaF7/+b9yc3OTv7+//P39Vbt2bQ0ZMkTHjh3Tn3/+aR2zd+9eNW/eXB4eHipdurS6d++u9PR06/s5OTkaNWqUKlSoIDc3N9WuXVsxMTHW969cuaJevXopICBA7u7uqlixosaPHy9JqlSpkiTpueeek8Visb7+62n33NncyZMnKyAgQKVLl1bPnj1tfhBISUnRU089JQ8PDz300EP68ssvValSJU2bNu2W+w8AAO4fRVY+z5w5ozVr1qhnz54qUaLETcdYLBab1++9956ee+457d27V126dFFOTo4qVKigRYsW6eeff9a7776rd955R19//bX1M1OmTFF0dLQ+//xzbd68WWfPntXSpUtvm61Xr17aunWrFixYoD179uill15Sq1at9Ouvv1rHXLx4UZMnT9Z///tfbdy4UUePHtXAgQMlXTtd3a5dO5sZzcaNG+fpuKSnp2vevHkKCgqyzjpmZGQoPDxcvr6+2rFjhxYtWqS1a9eqV69e1s99+OGHmjJliiZPnqw9e/YoPDxczzzzjDXzRx99pO+++05ff/21kpOTNX/+fGvJ3LFjhyRpzpw5SklJsb6+mdjYWB08eFCxsbGaO3euoqOjFR0dbX3/3//+t/744w/FxcVpyZIl+vTTT3Xq1Klbbi8zM1NpaWk2CwAAcFwuRfXFBw4ckGEYCg4OtllfpkwZXb58WZLUs2dPTZw40fpehw4d9Oqrr9qMHzlypPW/H3roIW3dulVff/212rVrJ0maNm2ahg4dqueff16SNGvWLK1evfqWuY4ePao5c+bo6NGjKleunKRrZTImJkZz5szRuHHjJF077T9r1iw9/PDDkq4V1lGjRkm6drraw8NDmZmZ8vf3v+OxWL58uUqWLCnpWtEMCAjQ8uXL5eR07WeDL7/8UpcvX9YXX3xhLeozZsxQmzZtNHHiRPn5+Wny5MkaPHiw/vWvf0mSJk6cqNjYWE2bNk0zZ87U0aNHVaVKFf3zn/+UxWJRxYoVrd//wAMPSJJ8fHzumNfX11czZsyQs7OzQkJC9NRTT2ndunXq1q2b9u/fr7Vr12rHjh2qV6+eJGn27NmqUqXKLbc3fvx4m/+HAADAsRX5DUd/tX37diUmJqpGjRrKzMy0eS+30Fxv5syZqlu3rh544AGVLFlSn376qY4ePSpJSk1NVUpKiho2bGgd7+LictPt5Nq7d6+ys7NVtWpVlSxZ0rps2LBBBw8etI4rXry4tXhKUkBAwG1n+G6nWbNmSkxMVGJiorZv367w8HC1bt1av/32myQpKSlJtWrVspkhDgsLU05OjpKTk5WWlqY//vhDYWFhNtsNCwtTUlKSpGunzBMTExUcHKw+ffpozZo1+cpao0YNOTs7W19fv9/JyclycXFRnTp1rO8HBQXJ19f3ltsbOnSoUlNTrcuxY8fylQsAANwbimzmMygoSBaLRcnJyTbrK1euLEny8PC44TN/PT2/YMECDRw4UFOmTFGjRo3k6emp999/X9u2bct3rvT0dDk7O+vHH3+0KVmSrLOTklSsWDGb9ywWyw3XkuZViRIlFBQUZH09e/ZseXt7KyoqSmPGjMnXNv+qTp06Onz4sFatWqW1a9eqXbt2atmypRYvXmzXdm623zk5OfnO5ebmJjc3t3x/HgAA3FuKbOazdOnSevzxxzVjxgxlZGTkaxvx8fFq3LixevTooUcffVRBQUE2s5Pe3t4KCAiwKaNZWVn68ccfb7nNRx99VNnZ2Tp16pSCgoJslrycQs/l6uqq7OzsfO2XxWKRk5OTLl26JEmqVq2adu/ebXOc4uPj5eTkpODgYHl5ealcuXKKj4+32U58fLyqV69ufe3l5aWXX35ZUVFRWrhwoZYsWaKzZ89KulYq85s3V3BwsLKyspSQkGBdd+DAAZ07d+5vbRcAADiOIj3t/vHHHysrK0v16tXTwoULlZSUpOTkZM2bN0/79++/Yebxr6pUqaKdO3dq9erV+uWXXzRixIgbbpbp27evJkyYoGXLlmn//v3q0aOHzp8/f8ttVq1aVR07dtS///1vffPNNzp8+LC2b9+u8ePHa8WKFXnet0qVKmnPnj1KTk7W6dOnb/toqMzMTJ04cUInTpxQUlKSevfurfT0dOvd/h07dpS7u7s6d+6sffv2KTY2Vr1791anTp3k5+cnSXr77bc1ceJELVy4UMnJyRoyZIgSExPVt29fSdLUqVP11Vdfaf/+/frll1+0aNEi+fv7y8fHx5p33bp1OnHiRL7LYkhIiFq2bKnu3btr+/btSkhIUPfu3eXh4XHDzWMAAOD+VGSn3SXp4YcfVkJCgsaNG6ehQ4fq+PHjcnNzU/Xq1TVw4ED16NHjtp9//fXXlZCQoJdfflkWi0Xt27dXjx49tGrVKuuYAQMGKCUlRZ07d5aTk5O6dOmi5557Tqmpqbfc7pw5czRmzBgNGDBAv//+u8qUKaN//OMfdj17s1u3boqLi1O9evWUnp6u2NhYNW3a9KZjY2JiFBAQIEny9PRUSEiIFi1aZB1fvHhxrV69Wn379lX9+vVVvHhxvfDCC5o6dap1G3369FFqaqoGDBigU6dOqXr16vruu++sN/t4enpq0qRJ+vXXX+Xs7Kz69etr5cqV1puapkyZov79+ysqKkrly5fXkSNH8ryv1/viiy/UtWtXNWnSRP7+/ho/frx++uknubu752t7AADAsViM/F6oCOTB8ePHFRgYqLVr16pFixZ3HJ+WliZvb2/92N6ikq7MlgIAUFCqRv+9y+sKSpHOfMLxrF+/Xunp6QoNDVVKSooGDRqkSpUqqUmTJkUdDQAA3AUonyhQV69e1TvvvKNDhw7J09NTjRs31vz582+4Sx4AANyfOO2Ouwqn3QEAKBx3y2n3u+4h8wAAAHBclE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8AgAAwDT8hiPcVXJ/w1Fqaqq8vLyKOg4AAChgzHwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8AgAAwDSUTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RMAAACmoXwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBqXog4A3EzIvEg5ebgVdQwAABzG8VcnFHUEScx8AgAAwESUTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RMAAACmoXwCAADANJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/m8T504cUK9e/dW5cqV5ebmpsDAQLVp00br1q2zGWcYhlq3bi2LxaJly5bddpsRERGyWCw2S6tWrQpxLwAAwL3GpagDwHxHjhxRWFiYfHx89P777ys0NFRXr17V6tWr1bNnT+3fv986dtq0abJYLHnedqtWrTRnzhzrazc3twLNDgAA7m2Uz/tQjx49ZLFYtH37dpUoUcK6vkaNGurSpYv1dWJioqZMmaKdO3cqICAgT9t2c3OTv79/gWcGAACOgdPu95mzZ88qJiZGPXv2tCmeuXx8fCRJFy9eVIcOHTRz5ky7ymRcXJzKli2r4OBgvfnmmzpz5sxtx2dmZiotLc1mAQAAjovyeZ85cOCADMNQSEjIbce99dZbaty4sZ599tk8b7tVq1b64osvtG7dOk2cOFEbNmxQ69atlZ2dfcvPjB8/Xt7e3tYlMDAwz98HAADuPZx2v88YhnHHMd99953Wr1+vhIQEu7b9r3/9y/rfoaGhqlmzph5++GHFxcWpRYsWN/3M0KFD1b9/f+vrtLQ0CigAAA6Mmc/7TJUqVWSxWGxuKvqr9evX6+DBg/Lx8ZGLi4tcXK79jPLCCy+oadOmef6uypUrq0yZMjpw4MAtx7i5ucnLy8tmAQAAjovyeZ8pVaqUwsPDNXPmTGVkZNzw/vnz5zVkyBDt2bNHiYmJ1kWSPvjgA5s72e/k+PHjOnPmTJ5vVgIAAI6P8nkfmjlzprKzs9WgQQMtWbJEv/76q5KSkvTRRx+pUaNG8vf31yOPPGKzSNKDDz6ohx56yLqdkJAQLV26VJKUnp6ut99+Wz/88IOOHDmidevW6dlnn1VQUJDCw8OLZD8BAMDdh2s+70OVK1fWrl27NHbsWA0YMEApKSl64IEHVLduXX3yySd53k5ycrJSU1MlSc7OztqzZ4/mzp2r8+fPq1y5cnriiSc0evRonvUJAACsLEZe7kABTJKWliZvb28FzOwnJw9KKwAABeX4qxOKOoIkTrsDAADARJRPAAAAmIbyCQAAANNQPgEAAGAayicAAABMQ/kEAACAaSifAAAAMA3lEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBqLYRhGUYcAcqWlpcnb21upqany8vIq6jgAAKCAMfMJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8AgAAwDSUTwAAAJiG8gkAAADTUD4BAABgGsonAAAATEP5BAAAgGkonwAAADAN5RMAAACmoXwCAADANJRPAAAAmMalqAMA1zMMQ5KUlpZWxEkAAIC9PD09ZbFYbjuG8om7ypkzZyRJgYGBRZwEAADYKzU1VV5eXrcdQ/nEXaVUqVKSpKNHj8rb27uI09xf0tLSFBgYqGPHjt3xLw4UHI570eC4Fx2OfdEw67h7enrecQzlE3cVJ6drlyF7e3vzl1IR8fLy4tgXAY570eC4Fx2OfdG4G447NxwBAADANJRPAAAAmIbyibuKm5ubIiMj5ebmVtRR7jsc+6LBcS8aHPeiw7EvGnfTcbcYuc+2AQAAAAoZM58AAAAwDeUTAAAApqF8AgAAwDSUTwAAAJiG8gnTzZw5U5UqVZK7u7saNmyo7du333b8okWLFBISInd3d4WGhmrlypUmJXUs9hz3qKgo/d///Z98fX3l6+urli1b3vH/E27N3j/zuRYsWCCLxaK2bdsWbkAHZe9xP3/+vHr27KmAgAC5ubmpatWq/H2TT/Ye+2nTpik4OFgeHh4KDAzUW2+9pcuXL5uU1jFs3LhRbdq0Ubly5WSxWLRs2bI7fiYuLk516tSRm5ubgoKCFB0dXeg5JUkGYKIFCxYYrq6uxueff2789NNPRrdu3QwfHx/j5MmTNx0fHx9vODs7G5MmTTJ+/vlnY/jw4UaxYsWMvXv3mpz83mbvce/QoYMxc+ZMIyEhwUhKSjIiIiIMb29v4/jx4yYnv/fZe+xzHT582Chfvrzxf//3f8azzz5rTlgHYu9xz8zMNOrVq2c8+eSTxubNm43Dhw8bcXFxRmJiosnJ7332Hvv58+cbbm5uxvz5843Dhw8bq1evNgICAoy33nrL5OT3tpUrVxrDhg0zvvnmG0OSsXTp0tuOP3TokFG8eHGjf//+xs8//2xMnz7dcHZ2NmJiYgo9K+UTpmrQoIHRs2dP6+vs7GyjXLlyxvjx4286vl27dsZTTz1ls65hw4bG66+/Xqg5HY29x/2vsrKyDE9PT2Pu3LmFFdFh5efYZ2VlGY0bNzZmz55tdO7cmfKZD/Ye908++cSoXLmyceXKFbMiOix7j33Pnj2N5s2b26zr37+/ERYWVqg5HVleyuegQYOMGjVq2Kx7+eWXjfDw8EJMdg2n3WGaK1eu6Mcff1TLli2t65ycnNSyZUtt3br1pp/ZunWrzXhJCg8Pv+V43Cg/x/2vLl68qKtXr6pUqVKFFdMh5ffYjxo1SmXLllXXrl3NiOlw8nPcv/vuOzVq1Eg9e/aUn5+fHnnkEY0bN07Z2dlmxXYI+Tn2jRs31o8//mg9NX/o0CGtXLlSTz75pCmZ71dF+e+rS6F/A/D/OX36tLKzs+Xn52ez3s/PT/v377/pZ06cOHHT8SdOnCi0nI4mP8f9rwYPHqxy5crd8BcVbi8/x37z5s367LPPlJiYaEJCx5Sf437o0CGtX79eHTt21MqVK3XgwAH16NFDV69eVWRkpBmxHUJ+jn2HDh10+vRp/fOf/5RhGMrKytIbb7yhd955x4zI961b/fualpamS5cuycPDo9C+m5lPALc1YcIELViwQEuXLpW7u3tRx3FoFy5cUKdOnRQVFaUyZcoUdZz7Sk5OjsqWLatPP/1UdevW1csvv6xhw4Zp1qxZRR3N4cXFxWncuHH6+OOPtWvXLn3zzTdasWKFRo8eXdTRUEiY+YRpypQpI2dnZ508edJm/cmTJ+Xv73/Tz/j7+9s1HjfKz3HPNXnyZE2YMEFr165VzZo1CzOmQ7L32B88eFBHjhxRmzZtrOtycnIkSS4uLkpOTtbDDz9cuKEdQH7+zAcEBKhYsWJydna2rqtWrZpOnDihK1euyNXVtVAzO4r8HPsRI0aoU6dOeu211yRJoaGhysjIUPfu3TVs2DA5OTFPVhhu9e+rl5dXoc56Ssx8wkSurq6qW7eu1q1bZ12Xk5OjdevWqVGjRjf9TKNGjWzGS9L3339/y/G4UX6OuyRNmjRJo0ePVkxMjOrVq2dGVIdj77EPCQnR3r17lZiYaF2eeeYZNWvWTImJiQoMDDQz/j0rP3/mw8LCdODAAWvZl6RffvlFAQEBFE875OfYX7x48YaCmftDgGEYhRf2Plek/74W+i1NwHUWLFhguLm5GdHR0cbPP/9sdO/e3fDx8TFOnDhhGIZhdOrUyRgyZIh1fHx8vOHi4mJMnjzZSEpKMiIjI3nUUj7Ye9wnTJhguLq6GosXLzZSUlKsy4ULF4pqF+5Z9h77v+Ju9/yx97gfPXrU8PT0NHr16mUkJycby5cvN8qWLWuMGTOmqHbhnmXvsY+MjDQ8PT2Nr776yjh06JCxZs0a4+GHHzbatWtXVLtwT7pw4YKRkJBgJCQkGJKMqVOnGgkJCcZvv/1mGIZhDBkyxOjUqZN1fO6jlt5++20jKSnJmDlzJo9aguOaPn268eCDDxqurq5GgwYNjB9++MH63mOPPWZ07tzZZvzXX39tVK1a1XB1dTVq1KhhrFixwuTEjsGe416xYkVD0g1LZGSk+cEdgL1/5q9H+cw/e4/7li1bjIYNGxpubm5G5cqVjbFjxxpZWVkmp3YM9hz7q1evGu+9957x8MMPG+7u7kZgYKDRo0cP49y5c+YHv4fFxsbe9O/t3GPduXNn47HHHrvhM7Vr1zZcXV2NypUrG3PmzDElq8UwmNMGAACAObjmEwAAAKahfAIAAMA0lE8AAACYhvIJAAAA01A+AQAAYBrKJwAAAExD+QQAAIBpKJ8AAAAwDeUTAAAApqF8AgAAwDSUTwAAAJiG8gkAAADT/D8Lxcv7QgD1NAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "dJI7Dd4lXMqe",
        "outputId": "8f91ca68-3ad7-46b3-f59c-3e4ff4a006a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were certainly able to achieve our initial goal of developing a predictive model that can accurately classify patients into survivability outcomes based on a set of features derived from the SEER database. Each of our models performed relatively well with a minimum accuracy score of 73.54, maximum accuracy score of 90.43%, and four of the five algorithms having an accuracy higher than 87%. Overall, we are proud of our results."
      ],
      "metadata": {
        "id": "99reQqX2Wp0_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}